{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmYA8nmCMfOy"
      },
      "source": [
        "# Chat with any documents using langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43Z6U7XNMl0A"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S6k29lnn-hF7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (0.27.4)\n",
            "Requirement already satisfied: langchain in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (0.0.327)\n",
            "Requirement already satisfied: unstructured in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (0.10.28)\n",
            "Requirement already satisfied: tiktoken in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (0.3.1)\n",
            "Requirement already satisfied: gradio in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (4.0.2)\n",
            "Requirement already satisfied: chromadb in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (0.4.15)\n",
            "Requirement already satisfied: pinecone-client in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (2.2.4)\n",
            "Requirement already satisfied: ndg-httpsclient in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (0.5.1)\n",
            "Requirement already satisfied: pyopenssl in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (23.3.0)\n",
            "Requirement already satisfied: pyasn1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (0.5.0)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from openai) (2.28.2)\n",
            "Requirement already satisfied: tqdm in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: anyio<4.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from langchain) (0.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from langchain) (0.0.54)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from langchain) (1.26.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from langchain) (2.4.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: chardet in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (4.9.3)\n",
            "Requirement already satisfied: nltk in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (4.12.2)\n",
            "Requirement already satisfied: emoji in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (2.8.0)\n",
            "Requirement already satisfied: python-iso639 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (2023.6.15)\n",
            "Requirement already satisfied: langdetect in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (3.4.0)\n",
            "Requirement already satisfied: backoff in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from unstructured) (4.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from tiktoken) (2023.3.23)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (23.1.0)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (5.1.2)\n",
            "Requirement already satisfied: fastapi in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (0.104.1)\n",
            "Requirement already satisfied: ffmpy in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.7.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (0.7.0)\n",
            "Requirement already satisfied: httpx in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (0.25.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (6.1.0)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: matplotlib~=3.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (3.8.1)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (3.9.10)\n",
            "Requirement already satisfied: packaging in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (2.0.0)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (10.1.0)\n",
            "Requirement already satisfied: pydub in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.9 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (0.23.2)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio) (11.0.3)\n",
            "Requirement already satisfied: fsspec in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from gradio-client==0.7.0->gradio) (2023.10.0)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: posthog>=2.4.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (3.0.2)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (3.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (1.16.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (1.20.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (0.14.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (7.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (1.59.2)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (4.0.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from chromadb) (28.1.0)\n",
            "Requirement already satisfied: loguru>=0.5.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from pinecone-client) (0.7.2)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from pinecone-client) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from pinecone-client) (1.26.15)\n",
            "Requirement already satisfied: cryptography<42,>=41.0.5 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from pyopenssl) (41.0.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from aiohttp->openai) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: jsonschema>=3.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from cryptography<42,>=41.0.5->pyopenssl) (1.16.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: filelock in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.11.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: certifi>=14.05.14 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.17.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.6.4)\n",
            "Requirement already satisfied: requests-oauthlib in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: colorama>=0.3.4 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
            "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
            "Requirement already satisfied: coloredlogs in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: protobuf in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.4)\n",
            "Requirement already satisfied: sympy in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.61.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.20.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.20.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.20.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.41b0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.41b0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
            "Requirement already satisfied: monotonic>=1.5 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (13.6.0)\n",
            "Requirement already satisfied: h11>=0.8 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from httpx->gradio) (0.18.0)\n",
            "Requirement already satisfied: joblib in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from nltk->unstructured) (1.3.2)\n",
            "Requirement already satisfied: pycparser in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from cffi>=1.12->cryptography<42,>=41.0.5->pyopenssl) (2.21)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.15.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyreadline3 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\x\\dev\\pythonprojects\\mia\\env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai langchain unstructured tiktoken gradio chromadb pinecone-client ndg-httpsclient pyopenssl pyasn1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EL9SFDqQ_F-O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import main\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone, Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v_3FRN1dAbGc"
      },
      "outputs": [],
      "source": [
        "main.load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "PINECONE_API_KEY = str(os.getenv(\"PINECONE_API_KEY\"))\n",
        "PINECONE_ENV = str(os.getenv(\"PINECONE_ENV_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'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'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVKH8f-mqowj"
      },
      "source": [
        "[LangChain Document Loader](https://python.langchain.com/en/latest/modules/indexes/document_loaders.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9bCdJGpTB8Dp"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "txt_loader = DirectoryLoader(r'.\\transcripts', glob=\"**/*.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYkYmqmEDPwv",
        "outputId": "e77957cb-eb05-4848-a575-824c2872d1c4"
      },
      "outputs": [],
      "source": [
        "#take all the loader\n",
        "loaders = [txt_loader]\n",
        "\n",
        "#lets create document \n",
        "documents = []\n",
        "for loader in loaders:\n",
        "    documents.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khg3Wm8zrNvm",
        "outputId": "ad4df0a6-db16-4d46-d2ab-98e633af443a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have 206 document(s) in your data\n",
            "There are 97 characters in your document\n"
          ]
        }
      ],
      "source": [
        "print (f'You have {len(documents)} document(s) in your data')\n",
        "print (f'There are {len(documents[153].page_content)} characters in your document')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx0j1rnwGW48",
        "outputId": "e5a9f956-dc7d-4c64-c4b7-d19ac607b648"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content=\"You don't want to know. All of this is just easily faked and easily manufactured and manipulated.\", metadata={'source': 'transcripts\\\\51.txt'})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[153]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01sK31QQGuQ1"
      },
      "source": [
        "## Split the Text from the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS6iEnTxGkku",
        "outputId": "ba436850-2429-4379-d92a-21ceb34b4d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "199\n"
          ]
        }
      ],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=40) #chunk overlap seems to work better\n",
        "documents = text_splitter.split_documents(documents)\n",
        "print(len(documents))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-pByaC1HHR9",
        "outputId": "d3bd31bc-43be-49c9-d521-bf28ccae2ed2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='People that drink bang are stupid and fat and no other way.', metadata={'source': 'transcripts\\\\57.txt'})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[153]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwYWEYf-HLF6",
        "outputId": "3081f1ce-4875-4792-a72c-829a7dd43236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content=\"It's interesting every fucking drink ever has this in it. It's not like bang on\", metadata={'source': 'transcripts\\\\55.txt'})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[151]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx6JtYgWHZvL"
      },
      "source": [
        "## Embeddings and storing it in Vectorestore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'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'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XI--vvaJHOgn"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdILt9zkMGWC"
      },
      "source": [
        "### Using pinecone for storing vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gbHwwRgI5n8"
      },
      "source": [
        "- [Pinecone langchain doc](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html?highlight=pinecone#pinecone\n",
        ")\n",
        "- What is [vectorstore](https://www.pinecone.io/learn/vector-database/)\n",
        "- Get your pinecone api key and env -> https://app.pinecone.io/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYsPAF3TJhmX"
      },
      "outputs": [],
      "source": [
        "import pinecone \n",
        "\n",
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
        "    environment=PINECONE_ENV  # next to api key in console\n",
        ")\n",
        "\n",
        "index_name = \"mia\"\n",
        "\n",
        "vectorstore = Pinecone.from_documents(documents, embeddings, index_name=index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "a4lCSdF6fTRo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "# if you already have an index, you can load it like this\n",
        "import pinecone\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
        "    environment=PINECONE_ENV  # next to api key in console\n",
        ")\n",
        "\n",
        "index_name = \"mia\"\n",
        "vectorstore = Pinecone.from_existing_index(index_name, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-7i5EkcNBnK"
      },
      "source": [
        "#### We had 23 documents so there are 23 vectors being created in Pinecone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dbUFZWoXJ3d2"
      },
      "outputs": [
        {
          "ename": "AuthenticationError",
          "evalue": "Incorrect API key provided: sk-45tko***************************************b7OO. You can find your API key at https://platform.openai.com/account/api-keys.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\test12_pinecone.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/X/Dev/PythonProjects/MIA/test12_pinecone.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mName an energy drink\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/X/Dev/PythonProjects/MIA/test12_pinecone.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m docs \u001b[39m=\u001b[39m vectorstore\u001b[39m.\u001b[39;49msimilarity_search(query)\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\langchain\\vectorstores\\pinecone.py:226\u001b[0m, in \u001b[0;36mPinecone.similarity_search\u001b[1;34m(self, query, k, filter, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search\u001b[39m(\n\u001b[0;32m    208\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    209\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    214\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[0;32m    215\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return pinecone documents most similar to query.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \n\u001b[0;32m    217\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimilarity_search_with_score(\n\u001b[0;32m    227\u001b[0m         query, k\u001b[39m=\u001b[39;49mk, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m, namespace\u001b[39m=\u001b[39;49mnamespace, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    228\u001b[0m     )\n\u001b[0;32m    229\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc \u001b[39mfor\u001b[39;00m doc, _ \u001b[39min\u001b[39;00m docs_and_scores]\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\langchain\\vectorstores\\pinecone.py:172\u001b[0m, in \u001b[0;36mPinecone.similarity_search_with_score\u001b[1;34m(self, query, k, filter, namespace)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search_with_score\u001b[39m(\n\u001b[0;32m    154\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    155\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    158\u001b[0m     namespace: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    159\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[Document, \u001b[39mfloat\u001b[39m]]:\n\u001b[0;32m    160\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return pinecone documents most similar to query, along with scores.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[0;32m    162\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimilarity_search_by_vector_with_score(\n\u001b[1;32m--> 172\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_query(query), k\u001b[39m=\u001b[39mk, \u001b[39mfilter\u001b[39m\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m, namespace\u001b[39m=\u001b[39mnamespace\n\u001b[0;32m    173\u001b[0m     )\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\langchain\\vectorstores\\pinecone.py:90\u001b[0m, in \u001b[0;36mPinecone._embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Embed query text.\"\"\"\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding, Embeddings):\n\u001b[1;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding\u001b[39m.\u001b[39;49membed_query(text)\n\u001b[0;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding(text)\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\langchain\\embeddings\\openai.py:518\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m    510\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \n\u001b[0;32m    512\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[39m        Embedding for the text.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_documents([text])[\u001b[39m0\u001b[39m]\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\langchain\\embeddings\\openai.py:490\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \n\u001b[0;32m    480\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\langchain\\embeddings\\openai.py:374\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    371\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[0;32m    373\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[1;32m--> 374\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[0;32m    375\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    376\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[0;32m    377\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[0;32m    378\u001b[0m     )\n\u001b[0;32m    379\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    381\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\langchain\\embeddings\\openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n\u001b[1;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\langchain\\embeddings\\openai.py:104\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\openai\\api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    615\u001b[0m         )\n\u001b[0;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     )\n",
            "File \u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\env\\Lib\\site-packages\\openai\\api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "\u001b[1;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-45tko***************************************b7OO. You can find your API key at https://platform.openai.com/account/api-keys."
          ]
        }
      ],
      "source": [
        "query = \"Name an energy drink\"\n",
        "docs = vectorstore.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSqHUoQRNmCI",
        "outputId": "3fedd512-9c1e-4f43-d493-beda1d8a49e2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'docs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\X\\Dev\\PythonProjects\\MIA\\test12_pinecone.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/X/Dev/PythonProjects/MIA/test12_pinecone.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mlen\u001b[39m(docs) \u001b[39m#it went on and search on the 4 different vectors to find the similarity\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'docs' is not defined"
          ]
        }
      ],
      "source": [
        "len(docs) #it went on and search on the 4 different vectors to find the similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmSZQsDENfiE",
        "outputId": "37363217-3098-4f2c-c646-8d991502abf5"
      },
      "outputs": [],
      "source": [
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyoXLl0YUqz1",
        "outputId": "d2af77a9-e59a-4d74-fe4a-da51e95ec8e1"
      },
      "outputs": [],
      "source": [
        "print(docs[1].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keEibikCN6-w"
      },
      "source": [
        "## Now the langchain part (Chaining with Chat History) --> With One line of Code (Fantastic)\n",
        "- There are many chains but we use this [link](https://python.langchain.com/en/latest/modules/chains/index_examples/chat_vector_db.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiSQ4IQCtDT8"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZGMwOuaNiHZ"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
        "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1TnRF83PMZV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LxpEcvZYoN3D",
        "outputId": "9b0c3539-9e1d-49f6-8e69-c8798680e391"
      },
      "outputs": [],
      "source": [
        "chat_history = []\n",
        "query = \"How much is spent for training the gpt4all model?\"\n",
        "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3QZzJ0D-6QY",
        "outputId": "67519e6c-488c-4948-d992-10236fab0a3a"
      },
      "outputs": [],
      "source": [
        "chat_history.append((query, result[\"answer\"]))\n",
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wtn22jDK_6Qj",
        "outputId": "eb65e3e9-b1a4-4680-c8b6-e7b215b4cc7a"
      },
      "outputs": [],
      "source": [
        "query = \"What is this number multiplied by 2?\"\n",
        "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5oduK4NVv1e"
      },
      "source": [
        "## Create a chatbot with memory with simple widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYMWTZoxV1Rq"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "import ipywidgets as widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "93bdfcd316b94785a9f63b54fb2e7eed",
            "194fcb196a394e8cb78d9e39ef9461c0",
            "87f711d699b443eeac5301e31e139210",
            "5434caeb5dc840a0a1996b7f1151e9d1",
            "52fddac56425425fb1b3f6c41a83ad40",
            "6119c20941e645fe85777d8a40134f45",
            "7ebbefa2c67d44a6bb7a1ceaf61f9b63",
            "da35600790c34a9db211e75bbd47d00b",
            "0a59ae49aefe454dac82fd3cfa509201",
            "9c92fcac4b2b44dabe4210335e479af6",
            "d30bddef5eff4ba39adbfc977d1b543d",
            "3f22048167ab4e6a99ff352e4881d6f5",
            "8217b151f57a44d68f2135fba059de9f",
            "96f4fd5d75874fa3a9ba1f6d74b86855",
            "cb41fc15e4e84ddea00a1a63544486b6"
          ]
        },
        "id": "Q88JFgfLV9hQ",
        "outputId": "b262ee30-8863-46b5-e6e0-7160c6f17bf9"
      },
      "outputs": [],
      "source": [
        "chat_history = []\n",
        "\n",
        "def on_submit(_):\n",
        "    query = input_box.value\n",
        "    input_box.value = \"\"\n",
        "    \n",
        "    if query.lower() == 'exit':\n",
        "        print(\"Thanks for the chat!\")\n",
        "        return\n",
        "    \n",
        "    result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "    chat_history.append((query, result['answer']))\n",
        "    \n",
        "    display(widgets.HTML(f'<b>User:</b> {query}'))\n",
        "    display(widgets.HTML(f'<b><font color=\"Orange\">Chatbot:</font></b> {result[\"answer\"]}'))\n",
        "\n",
        "print(\"Chat with your data. Type 'exit' to stop\")\n",
        "\n",
        "input_box = widgets.Text(placeholder='Please enter your question:')\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "display(input_box)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ0kvK0tOt_O"
      },
      "source": [
        "### Gradio sample example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "VoKW01NoOsml",
        "outputId": "e6719dab-8e98-4107-9522-d5cb482caddc"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        print(message)\n",
        "        print(chat_history)\n",
        "        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n",
        "        chat_history.append((message, bot_message))\n",
        "        print(chat_history)\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wDesKT8Oz8x"
      },
      "source": [
        "### Gradio langchain example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ug2RL9rdPXa4",
        "outputId": "095d2936-a255-4e17-8262-60014471c474"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.Button(\"Clear\")\n",
        "    \n",
        "    def respond(user_message, chat_history):\n",
        "        print(user_message)\n",
        "        print(chat_history)\n",
        "        # Get response from QA chain\n",
        "        response = qa({\"question\": user_message, \"chat_history\": chat_history})\n",
        "        # Append user message and response to chat history\n",
        "        chat_history.append((user_message, response[\"answer\"]))\n",
        "        print(chat_history)\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot], queue=False)\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9V1nvnA__OA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPZw2K7M/AjT+BeF+DKgYK4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a59ae49aefe454dac82fd3cfa509201": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "194fcb196a394e8cb78d9e39ef9461c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f22048167ab4e6a99ff352e4881d6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52fddac56425425fb1b3f6c41a83ad40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5434caeb5dc840a0a1996b7f1151e9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52fddac56425425fb1b3f6c41a83ad40",
            "placeholder": "​",
            "style": "IPY_MODEL_6119c20941e645fe85777d8a40134f45",
            "value": "<b>User:</b> who are the authors of gpt4al"
          }
        },
        "6119c20941e645fe85777d8a40134f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ebbefa2c67d44a6bb7a1ceaf61f9b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da35600790c34a9db211e75bbd47d00b",
            "placeholder": "​",
            "style": "IPY_MODEL_0a59ae49aefe454dac82fd3cfa509201",
            "value": "<b><font color=\"Orange\">Chatbot:</font></b>  The authors of GPT4All are Yuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin M. Schmidt, Adam Treat, and Andriy Mulyar."
          }
        },
        "8217b151f57a44d68f2135fba059de9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96f4fd5d75874fa3a9ba1f6d74b86855",
            "placeholder": "​",
            "style": "IPY_MODEL_cb41fc15e4e84ddea00a1a63544486b6",
            "value": "<b><font color=\"Orange\">Chatbot:</font></b> \n\nPandas AI is a Python library that adds generative artificial intelligence capabilities to Pandas, the popular data analysis and manipulation tool. It is designed to be used in conjunction with Pandas, and is not a replacement for it."
          }
        },
        "87f711d699b443eeac5301e31e139210": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93bdfcd316b94785a9f63b54fb2e7eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_194fcb196a394e8cb78d9e39ef9461c0",
            "placeholder": "Please enter your question:",
            "style": "IPY_MODEL_87f711d699b443eeac5301e31e139210",
            "value": ""
          }
        },
        "96f4fd5d75874fa3a9ba1f6d74b86855": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c92fcac4b2b44dabe4210335e479af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d30bddef5eff4ba39adbfc977d1b543d",
            "placeholder": "​",
            "style": "IPY_MODEL_3f22048167ab4e6a99ff352e4881d6f5",
            "value": "<b>User:</b> what is pandas ai "
          }
        },
        "cb41fc15e4e84ddea00a1a63544486b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d30bddef5eff4ba39adbfc977d1b543d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da35600790c34a9db211e75bbd47d00b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
